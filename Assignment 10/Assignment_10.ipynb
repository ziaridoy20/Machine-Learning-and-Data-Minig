{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10) # printing setup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This formula shall be imitated by the neural network\n",
    "def formula_1(x):\n",
    "    return x + 0.75\n",
    "\n",
    "# This formula shall be imitated by the neural network, too\n",
    "def formula_2(x):\n",
    "    return(np.sin(x) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.157054  ],\n",
       "       [1.20236735],\n",
       "       [1.33518883],\n",
       "       ...,\n",
       "       [0.15491996],\n",
       "       [0.30857138],\n",
       "       [0.96680288]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data\n",
    "X = np.random.uniform(low=-0.5, high=1.55, size=100)# make 100 uniformly distributed samples\n",
    "X = X.reshape(-1, 1) # -1 indicates \"as many rows as required\"\n",
    "X # input data as column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.907054  ],\n",
       "       [1.95236735],\n",
       "       [2.08518883],\n",
       "       ...,\n",
       "       [0.90491996],\n",
       "       [1.05857138],\n",
       "       [1.71680288]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target values with formula_1\n",
    "y_1 = np.array([formula_1(x) for x in X.flatten()]) # one output per sample, |X|-many samples\n",
    "y_1 = y_1.reshape(-1, 1)\n",
    "y_1 # target data as column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.41562268],\n",
       "       [1.4328943 ],\n",
       "       [1.47237271],\n",
       "       ...,\n",
       "       [0.65430101],\n",
       "       [0.8036978 ],\n",
       "       [1.32307417]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target values with formula_2\n",
    "y_2 = np.array([formula_2(x) for x in X.flatten()]) # one output per sample, |X|-many samples\n",
    "y_2 = y_2.reshape(-1, 1)\n",
    "y_2 # target data as column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below contains the parts to be edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural-network based regressor\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # Function called at object initialization\n",
    "    def __init__(self):\n",
    "        \n",
    "        # These are members of the class. You can access them in every method by \"self.var_name\" and from outside the class with \"instance_name.var_name\"\n",
    "        \n",
    "        # Sample to compute pass with\n",
    "        self.X          = 0.0 # set me!\n",
    "        self.y          = 0.0 # set me!\n",
    "        \n",
    "        # Parameters to be learned\n",
    "        self.weight_1   = 1.0 # teach me!\n",
    "        self.weight_2   = 1.0 # teach me!\n",
    "        self.bias       = 1.0 # teach me!\n",
    "        \n",
    "        # State information\n",
    "        self.hidden     = 0.0 # use me!\n",
    "        self.output     = 0.0 # use me!\n",
    "        self.error      = 0.0 # use me!\n",
    "        \n",
    "    # Set sample to be used in feed-forward and back-propagation pass\n",
    "    def set_sample(self, X, y):\n",
    "        self.X = float(X)\n",
    "        self.y = float(y)\n",
    "        \n",
    "    # (a) Feed-forward pass\n",
    "    def feed_forward(self):    \n",
    "               \n",
    "        self.X = np.dot(self.weight_1, self.X) + self.bias\n",
    "        self.y = np.dot (self.weight_2, self.Y) + self.bias\n",
    "        self.output =   self.set_sample(self, self.X, self.y)\n",
    "        return self.output    \n",
    "         \n",
    "      \n",
    "    # (b) Back-propagation pass\n",
    "    def back_prop(self):\n",
    "        \n",
    "        ### Incomplete back propagation...\n",
    "        \n",
    "        \n",
    "        \n",
    "def execute_nn(X, y):\n",
    "    \n",
    "    # Instantiate neural network\n",
    "    nn = NeuralNetwork()\n",
    "    \n",
    "    # Collect mean error of each epoch to plot it later\n",
    "    epoch_error = []\n",
    "\n",
    "    # Perform multiple epochs, aka inputting the dataset multiple times\n",
    "    for epoch in range(0,100):\n",
    "        nn = NeuralNetwork() # instantiates neural network\n",
    "        nn.set_sample(2,5) # sets sample with 2 as input and 5 as target\n",
    "        nn.feed_forward() # perform feed-forward to calculate output\n",
    "        nn.back_prop() # use difference between target and actual output to update parameters\n",
    "      \n",
    "        \n",
    "    # Print final parameters of trained neural network\n",
    "    print(\"Weight_1:\"+ str(nn.weight_1))\n",
    "    print(\"Weight_2:\" + str(nn.weight_2))\n",
    "    print(\"Bias:\" + str(nn.bias))\n",
    "    \n",
    "    # Plot epoch errors with logarithmic transformation\n",
    "    plt.plot(list(range(len(epoch_error))), np.log(epoch_error))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('# Epoch')\n",
    "    ax.set_ylabel('Error')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot datapoints as originally transformed and as transformed by neural network\n",
    "    computed = []\n",
    "    for i in range(0, X.shape[0]):\n",
    "        nn.set_sample(X[i], y[i])\n",
    "        nn.feed_forward()\n",
    "        computed.append(nn.output)\n",
    "    plt.scatter(X.transpose().flatten(), y.transpose().flatten(), c='blue', s=16)\n",
    "    plt.scatter(X.transpose().flatten(), computed, c='red', s=16)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Imitation of formula 'x+0.75'\")\n",
    "execute_nn(X,y_1)\n",
    "print()\n",
    "print(\"Imitation of formula 'sin(x)+0.5'\")\n",
    "execute_nn(X,y_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
